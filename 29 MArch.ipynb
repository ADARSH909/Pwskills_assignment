{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afc700-0eb5-4a44-8b3d-9b46f72bc404",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Lasso Regression:\n",
    "Lasso Regression, or L1 regularization, is a linear regression technique that adds a penalty term to the linear regression cost function.\n",
    "The penalty is based on the absolute values of the coefficients, encouraging sparsity by driving some coefficients to exactly zero. \n",
    "This has the effect of performing feature selection, as variables with zero coefficients are essentially excluded from the model.\n",
    "\n",
    "Differences from other regression techniques:\n",
    "\n",
    "    Feature Selection: Lasso is distinctive for its ability to perform feature selection by setting some coefficients to zero.\n",
    "    Shrinkage: It combines the principles of regularization (shrinkage of coefficients) with variable selection.\n",
    "\n",
    "Q2. Advantage of Lasso Regression in Feature Selection:\n",
    "The main advantage of Lasso Regression in feature selection is its ability to automatically eliminate irrelevant features by driving\n",
    "their corresponding coefficients to zero. This is particularly useful when dealing with high-dimensional datasets where not all features \n",
    "contribute significantly to the prediction. It simplifies the model and can enhance its interpretability.\n",
    "\n",
    "Q3. Interpretation of Lasso Regression Coefficients:\n",
    "In Lasso Regression, non-zero coefficients indicate the features that are selected and considered important for the model. \n",
    "The magnitude of the coefficients represents the strength of the effect of each corresponding feature on the target variable. \n",
    "A coefficient of zero means that the corresponding feature has been effectively excluded from the model.\n",
    "\n",
    "Q4. Tuning Parameters in Lasso Regression:\n",
    "The primary tuning parameter in Lasso Regression is the regularization parameter, often denoted as λλ (lambda). \n",
    "This parameter controls the strength of the penalty applied to the coefficients. A higher λλ increases the penalty,\n",
    "leading to more coefficients being driven to zero. The tuning parameter is crucial for balancing the trade-off between \n",
    "fitting the training data well and keeping the model simple.\n",
    "\n",
    "Q5. Lasso Regression for Non-linear Regression Problems:\n",
    "Lasso Regression, like standard linear regression, is inherently a linear method. However, it can be used for non-linear regression \n",
    "problems by incorporating non-linear transformations of the input features. For example, adding polynomial features or using other \n",
    "non-linear transformations before applying Lasso Regression can capture non-linear relationships between variables.\n",
    "\n",
    "Q6. Difference Between Ridge and Lasso Regression:\n",
    "Both Ridge and Lasso are regularization techniques, but they differ in the type of penalty applied to the coefficients:\n",
    "\n",
    "    Ridge Regression (L2 regularization): Adds a penalty term based on the squared values of the coefficients.\n",
    "    Lasso Regression (L1 regularization): Adds a penalty term based on the absolute values of the coefficients.\n",
    "\n",
    "The main distinction lies in how they handle the shrinkage of coefficients and perform feature selection. Ridge tends to shrink \n",
    "coefficients towards zero but rarely exactly to zero, while Lasso can lead to exactly zero coefficients, effectively performing\n",
    "feature selection.\n",
    "\n",
    "Q7. Handling Multicollinearity in Lasso Regression:\n",
    "Lasso Regression has a natural ability to handle multicollinearity to some extent due to its feature selection property. \n",
    "In the presence of highly correlated features, Lasso tends to select one feature from a group of correlated features and \n",
    "sets the coefficients of the remaining features to zero. This can be advantageous in scenarios where multicollinearity might\n",
    "pose a problem for other regression techniques.\n",
    "\n",
    "Q8. Choosing the Optimal Regularization Parameter in Lasso Regression:\n",
    "The optimal value of the regularization parameter (λλ) in Lasso Regression is typically chosen through cross-validation. \n",
    "The goal is to select the λλ that minimizes the prediction error on a validation set. Techniques such as k-fold cross-validation\n",
    "can be used to evaluate the model's performance for different values of λλ and identify the one that results in the best compromise \n",
    "between bias and variance. Grid search is often employed to search through a range of λλ values during this process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
