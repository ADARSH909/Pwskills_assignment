{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83bc66-bf68-4c38-b5b7-9a71fe04ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Difference between Linear Regression and Logistic Regression:\n",
    "\n",
    "    Linear Regression:\n",
    "        Used for predicting a continuous outcome (dependent variable) based on one or more independent variables.\n",
    "        The output is a linear combination of the input features.\n",
    "        The predicted values can be any real number.\n",
    "\n",
    "    Logistic Regression:\n",
    "        Used for predicting the probability of an event (binary outcome, usually 0 or 1) based on one or more independent variables.\n",
    "        The output is transformed using the logistic function (sigmoid function) to ensure it lies between 0 and 1.\n",
    "        Suitable for classification problems.\n",
    "\n",
    "Example:\n",
    "\n",
    "    Linear Regression: Predicting house prices based on features like square footage, number of bedrooms, etc.\n",
    "    Logistic Regression: Predicting whether an email is spam or not based on features like sender, subject, etc.\n",
    "\n",
    "Q2. Cost function used in logistic regression and optimization:\n",
    "\n",
    "    Cost Function:\n",
    "        Logistic regression uses the logistic loss (or cross-entropy loss) as the cost function.\n",
    "        For a single observation, the cost is defined as the negative log-likelihood of the true class.\n",
    "\n",
    "    Optimization:\n",
    "        Common optimization algorithms like gradient descent are used to minimize the cost function.\n",
    "        The model parameters (weights) are adjusted iteratively to find the optimal values that minimize the cost.\n",
    "\n",
    "Q3. Regularization in Logistic Regression:\n",
    "\n",
    "    Concept:\n",
    "        Regularization adds a penalty term to the cost function to prevent overfitting.\n",
    "        It discourages the model from fitting the noise in the training data.\n",
    "\n",
    "    Preventing Overfitting:\n",
    "        Common regularization terms are L1 regularization (lasso) and L2 regularization (ridge).\n",
    "        They control the size of the coefficients, preventing them from becoming too large.\n",
    "\n",
    "Q4. ROC Curve in Logistic Regression:\n",
    "\n",
    "    ROC Curve:\n",
    "        ROC (Receiver Operating Characteristic) curve is a graphical representation of the trade-off between true positive rate\n",
    "        (sensitivity) and false positive rate (1-specificity).\n",
    "        It helps visualize the performance of a binary classification model at various thresholds.\n",
    "\n",
    "Q5. Feature Selection Techniques:\n",
    "\n",
    "    Common Techniques:\n",
    "        Forward selection, backward elimination, recursive feature elimination.\n",
    "        Regularization techniques (L1 regularization can lead to automatic feature selection).\n",
    "        Feature importance from tree-based models.\n",
    "\n",
    "Q6. Handling Imbalanced Datasets:\n",
    "\n",
    "    Strategies:\n",
    "        Resampling techniques (oversampling minority class, undersampling majority class).\n",
    "        Using different evaluation metrics (precision, recall, F1-score) rather than accuracy.\n",
    "        Generating synthetic samples (SMOTE - Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "Q7. Common Issues in Logistic Regression:\n",
    "\n",
    "    Multicollinearity:\n",
    "        Detect using variance inflation factor (VIF) and address by removing or combining correlated variables.\n",
    "\n",
    "    Other Issues:\n",
    "        Outliers: Identify and handle outliers appropriately.\n",
    "        Non-linearity: Consider adding interaction terms or using polynomial features.\n",
    "        Model Interpretability: Logistic regression assumes a linear relationship; complex non-linear relationships may not be captured well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
